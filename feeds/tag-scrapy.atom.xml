<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>mx's blog</title><link href="https://x-wei.github.io/" rel="alternate"></link><link href="https://x-wei.github.io/feeds/tag-scrapy.atom.xml" rel="self"></link><id>https://x-wei.github.io/</id><updated>2015-04-19T00:00:00+02:00</updated><entry><title>Scrapy 上手笔记</title><link href="https://x-wei.github.io/Scrapy%20%E4%B8%8A%E6%89%8B%E7%AC%94%E8%AE%B0.html" rel="alternate"></link><published>2015-04-19T00:00:00+02:00</published><updated>2015-04-19T00:00:00+02:00</updated><author><name>mx</name></author><id>tag:x-wei.github.io,2015-04-19:Scrapy 上手笔记.html</id><summary type="html">&lt;p&gt;Scrapy是用来爬取数据的很流行的包, 这里小记一下. 以前几天做的&lt;a href="https://github.com/X-Wei/OneArticleCrawler"&gt;一个爬虫&lt;/a&gt;为例子, 这个爬虫把韩寒一个app的前九百多期的文章抓了下来. &lt;/p&gt;
&lt;h2 id="i-installation"&gt;I. installation&lt;/h2&gt;
&lt;p&gt;scrapy的安装参考: &lt;a href="http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/ubuntu.html"&gt;http://scrapy-chs.readthedocs.org/zh_CN/latest/topics/ubuntu.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(直接pip安装的好像缺少什么包)&lt;/p&gt;
&lt;h2 id="ii-prerequisite"&gt;II. prerequisite&lt;/h2&gt;
&lt;h3 id="xpath"&gt;XPath&lt;/h3&gt;
&lt;p&gt;需要学习scrapy首先需要会XPath, 这是一种方便与在html/xml文档里查找所需元素的语句. 这个还是很好学的, 其实只需要花一刻钟时间看看w3school的&lt;a href="http://www.w3school.com.cn/xpath/"&gt;教程&lt;/a&gt;, 就可以掌握够用的知识进行下一步了. &lt;/p&gt;
&lt;p&gt;这里总结一下我觉得会用到的语句(不全, 不过经常用到): &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;//book&lt;/code&gt;    选取所有名字叫做book的元素&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bookstore/book&lt;/code&gt; 选取bookstore的子元素中所有叫book的元素&lt;/li&gt;
&lt;li&gt;&lt;code&gt;//title[@lang='eng']&lt;/code&gt; 选取lang属性为"eng"的所有title元素&lt;/li&gt;
&lt;li&gt;&lt;code&gt;//titile/text()&lt;/code&gt; 选取title元素的文字内容&lt;/li&gt;
&lt;li&gt;&lt;code&gt;descendant-or-self::text()&lt;/code&gt;: 选取自己或者所有后代节点的文字内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外还有个在线测试XPath语句的网站, 可以用这个测试XPath语句: &lt;/p&gt;
&lt;p&gt;&lt;a href="http://xpath.online-toolz.com/tools/xpath-editor.php"&gt;http://xpath.online-toolz.com/tools/xpath-editor.php&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="shen-cha-yuan-su"&gt;审查元素&lt;/h3&gt;
&lt;p&gt;再一个就是要用chrome的"审查元素"功能, 用这个功能可以看到想查找的网页内容对应在html文件的位置, 甚至可以直接右键复制想要的元素的XPath......(不过有时候并不是最合理的, 所以刚才XPath也不是白学...)&lt;/p&gt;
&lt;h2 id="iii-scrapy-shell_1"&gt;III. scrapy shell&lt;/h2&gt;
&lt;p&gt;网上的教程一般是从一个&lt;a href="http://doc.scrapy.org/en/latest/intro/tutorial.html"&gt;tutorial&lt;/a&gt;开始的, 介绍了一个小项目, 但是我觉得从scrapy shell开始应该更合理, 有时候甚至没必要建立一个工程, 在这个shell里就可以抓到想要的数据. &lt;/p&gt;
&lt;p&gt;启动的办法很简单: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;$scrapy shell 'url'&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;其中&lt;code&gt;url&lt;/code&gt;就写想要爬取的一个网址. &lt;/p&gt;
&lt;p&gt;这个shell简单说来, 就是一个测试爬虫的交互环境, 除了&lt;em&gt;多了一些特殊变量和函数&lt;/em&gt;, 就是一个普通的(i)python shell. &lt;/p&gt;
&lt;p&gt;先说两个scrapy shell多出来的变量: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;response&lt;/code&gt;: 把启动的&lt;code&gt;url&lt;/code&gt;抓取后得到的&lt;code&gt;Response&lt;/code&gt;对象, 比如 &lt;code&gt;response.body&lt;/code&gt;就包含了抓取来的html内容&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sel&lt;/code&gt;: 用刚刚抓取的内容建立的一个&lt;code&gt;Selector&lt;/code&gt;对象, 简单理解, Selector对象可以让我们执行XPath语句提取想要的内容&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;经常的用法就是用&lt;code&gt;response&lt;/code&gt;对象查看爬取的情况(&lt;code&gt;response.status&lt;/code&gt;), 用&lt;code&gt;sel&lt;/code&gt;对象测试XPath的正确:
&lt;code&gt;sel.xpath("xpath_statement").extract()&lt;/code&gt; 会在获取的response.body里用xpath查找并提取内容. &lt;/p&gt;
&lt;p&gt;再说两个scrapy shell添加的函数:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fetch(request_or_url)&lt;/code&gt;: 修改请求或者网址, 这样scrapy shell会从新用这个request/url抓取数据, 相应的sel和response等对象也会自动更新. &lt;/li&gt;
&lt;li&gt;&lt;code&gt;view(response)&lt;/code&gt;: 在浏览器里查看刚刚抓取的内容.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里举个例子, 抓取一个的文章标题: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;shell&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s1"&gt;'http://wufazhuce.com/one/vol.921#articulo'&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;......&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="ow"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;Out&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="ow"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'//*[@id="tab-articulo"]/div/h2/text()'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="k"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;ScrapyDeprecationWarning&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"sel"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;shortcut&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;is&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;deprecated&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;Use&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"response.xpath()"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"response.css()"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;or&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ss"&gt;"response.selector"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;instead&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="k"&gt;Out&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;2&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;u'\n\t\t\t\t\t\t\u78b0\u4e0d\u5f97\u7684\u4eba\t\t\t  \t\t'&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="ow"&gt;In&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;3&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;sel&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'//*[@id="tab-articulo"]/div/h2/text()'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="k"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;&lt;span class="w"&gt;                            &lt;/span&gt;&lt;span class="n"&gt;碰不得的人&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;scrapy shell的完整文档在: 
&lt;a href="http://doc.scrapy.org/en/latest/topics/shell.html"&gt;http://doc.scrapy.org/en/latest/topics/shell.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="iv-scrapy-project"&gt;IV. scrapy project&lt;/h2&gt;
&lt;p&gt;接下来说建立scrapy工程, 这个按照tutorial走就好了. 
建立工程: 
&lt;code&gt;scrapy startproject my_proj&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;会新建一个my_proj文件夹, 里面的结构是: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;$ tree &lt;/span&gt;
&lt;span class="code-line"&gt;.&lt;/span&gt;
&lt;span class="code-line"&gt;└── my_proj&lt;/span&gt;
&lt;span class="code-line"&gt;    ├── scrapy.cfg&lt;/span&gt;
&lt;span class="code-line"&gt;    └── my_proj&lt;/span&gt;
&lt;span class="code-line"&gt;        ├── __init__.py&lt;/span&gt;
&lt;span class="code-line"&gt;        ├── items.py&lt;/span&gt;
&lt;span class="code-line"&gt;        ├── pipelines.py&lt;/span&gt;
&lt;span class="code-line"&gt;        ├── settings.py&lt;/span&gt;
&lt;span class="code-line"&gt;        └── spiders&lt;/span&gt;
&lt;span class="code-line"&gt;            └── __init__.py&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;要修改的文件主要有两个: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;items.py&lt;/code&gt; 定义要抓取的数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spiders/xxx.py&lt;/code&gt; 定义自己的爬虫&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="1-zi-ding-yi-pa-chong"&gt;1. 自定义爬虫&lt;/h3&gt;
&lt;p&gt;先定义爬虫, 在spiders文件夹里面, 新建一个python文件, 这里定义一个&lt;code&gt;scrapy.spider.Spider&lt;/code&gt;的子类: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;OneSpider&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;spider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Spider&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"one_spider"&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;start_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"http://wufazhuce.com/one/vol.&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s2"&gt;#articulo"&lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;924&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;title_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'//*[@id="tab-articulo"]/div/h2/text()'&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;        &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里, Spider子类一定需要定义三个东西: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;：　 是爬虫的名字, 一会爬取的时候需要&lt;/li&gt;
&lt;li&gt;&lt;code&gt;start_urls&lt;/code&gt;:　启动时进行爬取的url列表&lt;/li&gt;
&lt;li&gt;&lt;code&gt;parse()&lt;/code&gt; 方法&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;爬虫启动的时候会把每一个start_urls里的网址下载, 生成的&lt;code&gt;Response&lt;/code&gt;对象会传入这个&lt;code&gt;parse()&lt;/code&gt;方法, 这个方法负责解析返回的&lt;code&gt;Response&lt;/code&gt;对象, 提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象等...&lt;/p&gt;
&lt;h3 id="2-bao-cun-zhua-qu-de-xin-xi-dao-item"&gt;2. 保存抓取的信息到item&lt;/h3&gt;
&lt;p&gt;刚才只是做到了抓取需要的信息, 还没有能够保存到文件里, 下面要将抓取的信息做成一个&lt;code&gt;Item&lt;/code&gt;保存.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;首先定义要保存的信息:&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;修改items.py文件, 里面定义一个&lt;code&gt;scrapy.Item&lt;/code&gt;的子类:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;OnearticleItem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="c1"&gt;# define the fields for your item here like:&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;vol&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;author&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这个文件很简单, 只是说明一下要抓取的信息, 他们都是&lt;code&gt;scrapy.Field()&lt;/code&gt;, 这个东西类似一个字典.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;然后在爬虫里保存item:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了保存抓取的内容, 在parse()方法里, 得到需要的数据以后, 新建一个&lt;code&gt;OnearticleItem&lt;/code&gt;, 把抓到的内容放进这个item里, 然后返回这个item即可. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="code-line"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;nb&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'\d+'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;title_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'//*[@id="tab-articulo"]/div/h2/text()'&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;author_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'//*[@id="tab-articulo"]/div/p/text()'&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;content_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'//div[@class="articulo-contenido"]/descendant-or-self::text()'&lt;/span&gt; &lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;author&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;author_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;content&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;  &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;content_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;   &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="n"&gt;nb&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;author&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;OnearticleItem&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'vol'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nb&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'title'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'author'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;author&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'content'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;content&lt;/span&gt;&lt;/span&gt;
&lt;span class="code-line"&gt;    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="3-yun-xing-pa-chong"&gt;3. 运行爬虫&lt;/h3&gt;
&lt;p&gt;以上的文件修改好了以后, 只需&lt;em&gt;在命令行里&lt;/em&gt;启动爬虫即可, 这时候就用到了刚才定义的spider的&lt;code&gt;name&lt;/code&gt;属性:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$scrapy crawl one_spider -o one.csv&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;大约几分钟功夫, 九百多篇文章就放到了one.csv文件里~&lt;/p&gt;</summary><category term="python"></category><category term="scrapy"></category></entry></feed>